{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Basic utilities for the other notebooks."
      ],
      "metadata": {
        "id": "BAf9-IFPsR2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "metadata": {
        "id": "ZfdpwqCdvyrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json"
      ],
      "metadata": {
        "id": "oXISRdtFX-R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "bvwMoYmhsk4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(history: tf.keras.callbacks.History, n_epochs=None):\n",
        "    \"\"\"\n",
        "    Plots training and validation loss of a given experiment.\n",
        "    :param n_epochs: If None, takes its value as the length of the history.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    n_epochs = n_epochs or len(history.history['loss'])\n",
        "    epochs = np.arange(1, n_epochs+1)\n",
        "    trainLoss, validationLoss = history.history['loss'][:n_epochs], history.history['val_loss'][:n_epochs]\n",
        "    ax.plot(epochs, trainLoss, label='Training Loss')\n",
        "    ax.plot(epochs, validationLoss, label='Validation Loss')\n"
      ],
      "metadata": {
        "id": "FYxY2uufsmTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(\n",
        "    history: tf.keras.callbacks.History, start_epoch=0, end_epoch=None,\n",
        "    metrics: str | list[str] = 'loss', data_labels = [('Training Loss', 'Validation Loss')],\n",
        "    axes_labels = [('Epochs', 'Value')]\n",
        "):\n",
        "  \"\"\"\n",
        "  Plots a specified set of metrics monitored by keras for training and validation,\n",
        "  each one in a separate figure.\n",
        "  :param start_epoch: First (included) epoch whose metric values are plotted.\n",
        "  :param end_epoch: Last (excluded) epoch whose metric values are plotted.\n",
        "  :param metrics: List of metrics as they are registered in `history`.\n",
        "  :param data_labels: Labels for each figure, in the same order as the metric names\n",
        "  in `metrics`.\n",
        "  :param axes_labels: Labels for the axes of each figure, in the same order as the metric names\n",
        "  in `metrics`.\n",
        "  \"\"\"\n",
        "  metrics = [metrics] if isinstance(metrics, str) else metrics\n",
        "  fig, ax = plt.subplots(len(metrics), 1)\n",
        "  end_epoch = end_epoch or len(history.history['loss'])\n",
        "  epochs = np.arange(start_epoch, end_epoch)\n",
        "  for i, (metric, metric_data_labels, metric_axes_labels) \\\n",
        "    in enumerate(zip(metrics, data_labels, axes_labels)):\n",
        "    ax[i].set_xlabel(metric_axes_labels[0])\n",
        "    ax[i].set_ylabel(metric_axes_labels[1])\n",
        "    ax[i].plot(epochs, history.history[metric][start_epoch:end_epoch], label=metric_data_labels[0])\n",
        "    ax[i].plot(epochs, history.history[f'val_{metric}'][start_epoch:end_epoch], label=metric_data_labels[1])\n",
        "    ax[i].legend()"
      ],
      "metadata": {
        "id": "P16tdnSDDn48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_relative_errors(predictions, targets, epsilon=1e-8, max_error=1, nbins=20):\n",
        "  \"\"\"\n",
        "  Plots relative errors adjusted by a small constant to avoid divisions by 0.\n",
        "  Relative errors are defined as: ||y_i + epsilon - ypred_i||/||y_i + epsilon||.\n",
        "  :param predictions: Predicted values (e.g. validation or test set).\n",
        "  :param targets: Ground truth values.\n",
        "  :param epsilon: Constant to add to `targets` when calculating relative errors.\n",
        "  :param max_error: Maximum value for the relative errors to be plotted.\n",
        "  :param nbins: Number of bins for the histogram plot.\n",
        "  \"\"\"\n",
        "  differences = np.abs(predictions - targets - epsilon)\n",
        "  relative_errors = differences / np.abs(targets + epsilon)\n",
        "  relative_errors_x = relative_errors[:, 0]\n",
        "  relative_errors_y = relative_errors[:, 1]\n",
        "  relative_errors_z = relative_errors[:, 2]\n",
        "  print(len(relative_errors_x), len(relative_errors_y), len(relative_errors_z))\n",
        "  # Prune the cases of a zero target (multiplies by 10**6 the error)\n",
        "  relative_errors_x = relative_errors_x[targets[:, 0] != 0]\n",
        "  relative_errors_y = relative_errors_y[targets[:, 1] != 0]\n",
        "  relative_errors_z = relative_errors_z[targets[:, 2] != 0]\n",
        "  print(len(relative_errors_x), len(relative_errors_y), len(relative_errors_z))\n",
        "  fig, ax = plt.subplots(3, 1)\n",
        "  ax[0].hist(\n",
        "      relative_errors_x, bins=np.linspace(0, max_error, nbins), label='Relative Error (x)'\n",
        "  )\n",
        "  ax[1].hist(\n",
        "      relative_errors_y, bins=np.linspace(0, max_error, nbins), label='Relative Error (y)'\n",
        "  )\n",
        "  ax[2].hist(\n",
        "      relative_errors_z, bins=np.linspace(0, max_error, nbins), label='Relative Error (z)'\n",
        "  )\n",
        "  print(f'x-axis: mean = {np.mean(relative_errors_x)}, std = {np.std(relative_errors_x)}')\n",
        "  print(f'y-axis: mean = {np.mean(relative_errors_y)}, std = {np.std(relative_errors_y)}')\n",
        "  print(f'z-axis: mean = {np.mean(relative_errors_z)}, std = {np.std(relative_errors_z)}')\n",
        "  for i in range(3):\n",
        "    ax[i].set_xlabel('Error')\n",
        "    ax[i].set_ylabel('Frequency')"
      ],
      "metadata": {
        "id": "6bb7WKoFIeu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **`Mean Euclidean Error`**:"
      ],
      "metadata": {
        "id": "qSX1Bo5y_hYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_euclidean_error(y_true, y_pred):\n",
        "  squared_difference = tf.math.square(y_true - y_pred)\n",
        "  return tf.math.sqrt(tf.math.reduce_sum(squared_difference, axis=-1))"
      ],
      "metadata": {
        "id": "YALlAMhR-WlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Retrieval\n",
        "The original dataset is made up of $513$ `full-hd` ($1920 \\times 1080$) images in `png` format. While in this format a single image requires $\\approx 100$ KB of memory, a `numpy` array that contains the image in `float32` datatype will require at least $1920 \\times 1080 \\times 3 \\times 4 \\approx 24$ MB of memory, hence the whole dataset will require $\\approx 12$ GB and would be unfeasible.\n",
        "\n",
        "For simplicity, we then define a `get_dataset()` function that resizes all the images to a percentage of the original size through the `PIL.Image.Image.thumbnail()` method. By default we operate with a size of $240 \\times 135$ ($12.5\\%$ of original width and height values)."
      ],
      "metadata": {
        "id": "dNhsAU6kb8WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(\n",
        "    image_data_path='data/image/ws_0.5', motion_data_path='data/motion/ws_0.5.npz',\n",
        "    resize=True, force_resize=True, target_size_perc=0.125, rescale_coordinates=1,\n",
        "    target_size=None,\n",
        "  ): # by default 135 x 240\n",
        "  \"\"\"\n",
        "  Returns the already loaded dataset with the images in the given size.\n",
        "  Parameters:\n",
        "    image_data_path (str): Path to the directory containing the image data. Default is 'data/image/ws_0.5'.\n",
        "    motion_data_path (str): Path to the motion data file. Default is 'data/motion/ws_0.5.npz'.\n",
        "    resize (bool): Flag to enable resizing of the images. Default is True.\n",
        "    force_resize (bool): Flag to force image resizing even if resized images already exist. Default is True.\n",
        "    target_size_perc (float): Percentage of the target image size relative to the original size. Default is 0.125.\n",
        "    rescale_coordinates (float): Scaling factor for the tip position coordinates. Default is 1.\n",
        "    target_size (tuple): Tuple specifying the target height and width of the images. Default is None.\n",
        "\n",
        "Returns:\n",
        "    tuple: A tuple containing two elements:\n",
        "        - images (numpy.ndarray): A numpy array of shape (num_images, height, width, channels) representing the images.\n",
        "        - tip_pos (numpy.ndarray): A numpy array of shape (num_images, 3) representing the rescaled tip positions.\n",
        "  \"\"\"\n",
        "  if target_size:\n",
        "    target_height, target_width = target_size\n",
        "  else:\n",
        "    target_height, target_width = int(1080 * target_size_perc), int(1920 * target_size_perc)\n",
        "  resized_dir_path = os.path.join(image_data_path, f'resized_{target_height}x{target_width}')\n",
        "  # Resizes images to given size\n",
        "  if force_resize or (resize and not os.path.exists(resized_dir_path)):\n",
        "    os.makedirs(resized_dir_path, exist_ok=True)\n",
        "    pngs = sorted(list(glob.glob(f'{image_data_path}/*.png')))\n",
        "    for i, png in enumerate(pngs):\n",
        "      image = PIL.Image.open(png)\n",
        "      image = image.resize((target_width, target_height))\n",
        "      image.save(os.path.join(resized_dir_path, f'{i}.png'), \"PNG\")\n",
        "  pngs = sorted(list(glob.glob(f'{resized_dir_path}/*.png')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
        "  images = np.zeros((len(pngs), target_height, target_width, 3), dtype=np.float32)\n",
        "  for i, png in enumerate(pngs):\n",
        "    images[i][:, :, :] = np.array(PIL.Image.open(png))\n",
        "  motion_data = np.load(motion_data_path)\n",
        "  tip_pos = rescale_coordinates * motion_data['position_rod1'][:, [2, 0, 1], -1]  # all positions of last node ([2,0,1] converts to xyz)\n",
        "  return images / 255.0, tip_pos"
      ],
      "metadata": {
        "id": "BZqQ2l6P8Hv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, a train-validation-test split function for Holdout-based model selection."
      ],
      "metadata": {
        "id": "wg1KdfzPsKXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def holdout_split(train_perc: float, eval_perc: float, test_perc: float, images, tip_pos):\n",
        "  dev_images, test_images, dev_tip_pos, test_tip_pos = train_test_split(images, tip_pos, test_size=test_perc, random_state=0)\n",
        "  train_images, eval_images, train_tip_pos, eval_tip_pos = train_test_split(\n",
        "      dev_images, dev_tip_pos, test_size=eval_perc/(eval_perc + train_perc), random_state=0\n",
        "  )\n",
        "  return (train_images, train_tip_pos), (eval_images, eval_tip_pos), (test_images, test_tip_pos)"
      ],
      "metadata": {
        "id": "7Vl-cy6xrtY9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}